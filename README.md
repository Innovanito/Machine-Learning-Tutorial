# Machine-Learning-Tutorial with Code Basics

I learned Mechine-Learning with youtuber Code Basics

And Here is the things that I learned through it

- Bagging: <br /> A technique for ensemble learning, where multiple models are trained on different subsets of the data to reduce variance and improve performance.

- Decision Tree: <br />A tree-like model that makes decisions by recursively splitting the data based on features, with each split maximizing the information gain.

- Hyperparameter Tuning: <br />The process of selecting the best hyperparameters for a model by trying different combinations and evaluating performance.

- K-Fold Cross Validation:<br /> A technique for evaluating a model's performance by splitting the data into K subsets, training on K-1 subsets and evaluating on the remaining subset, and repeating K times with a different subset as the test set each time.

- K-Means Clustering Algorithm: <br />A clustering algorithm that partitions data into K clusters based on their similarity, where K is a pre-defined number.

- K- Nearest Neighbors Classification: <br />A classification algorithm that predicts the class of a data point based on the class of its K nearest neighbors in the training data.

- L1 and L2 Regularization: <br />Techniques for preventing overfitting in a model by adding a penalty term to the loss function that encourages small weights (L1) or small weights squared (L2).

- Logistic Regression:<br /> A classification algorithm that models the probability of a binary outcome (e.g., yes/no) as a function of the input features.

- Naive Bayes Classifier Algorithm: <br />A classification algorithm based on Bayes' theorem, which models the probability of a class given the input features.

- Principle Component Analysis (PCA): <br />A technique for reducing the dimensionality of data by finding the principal components that explain the most variance.

- Random Forest: <br />An ensemble learning technique that trains multiple decision trees on random subsets of the data and features, and combines their predictions.

- Support Vector Machine:<br /> A classification algorithm that finds the hyperplane that maximally separates the data into different classes, or that maximizes the margin between the classes.


## Thoughs about learning the concept of Mechine-Learning

In learning process of Mechine-Learning, I first learn the core concept of the theory and I do exercise how does this theory apply to the model.

I was very surprised that I can use various kind of theory to analyze the data, and make model using many kinds of theory.

For example, when I want to predict what kind of flower is the given picture is, I can use Support Vector Mechine, and Random Forest, and K-Means Clustering.

But I found it interesting because even though I can make models using various kinds of theory, the Prediction Accuracy varies from data to data.

In order to increase the prediction accuracy, I learned that I have to tune parameter and hyperparameter of the each algorithm.
